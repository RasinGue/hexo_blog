<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GVGAI Book Chapter 3 - Planning in GVGAI - Rasin&#039;s Blog</title><meta description="书籍网站本章原文本章练习  简介Planning是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础"><meta property="og:type" content="blog"><meta property="og:title" content="GVGAI Book Chapter 3 - Planning in GVGAI"><meta property="og:url" content="https://rasin.me/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/"><meta property="og:site_name" content="Scienage Mafelteens"><meta property="og:description" content="书籍网站本章原文本章练习  简介Planning是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413151308.png"><meta property="og:image" content="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413162718.png"><meta property="article:published_time" content="2021-04-12T10:35:55.000Z"><meta property="article:modified_time" content="2021-04-15T13:10:12.967Z"><meta property="article:author" content="Rasin Gue"><meta property="article:tag" content="GVGAI; AI"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413151308.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://rasin.me/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/"},"headline":"Rasin's Blog","image":["https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413151308.png","https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413162718.png"],"datePublished":"2021-04-12T10:35:55.000Z","dateModified":"2021-04-15T13:10:12.967Z","author":{"@type":"Person","name":"Rasin Gue"},"description":"书籍网站本章原文本章练习  简介Planning是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础"}</script><link rel="canonical" href="https://rasin.me/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-166789681-2" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-166789681-2');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Rasin&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2021-04-12T10:35:55.000Z" title="2021-04-12T10:35:55.000Z">2021-04-12</time><span class="level-item">21 分钟 读完 (大约 3113 个字)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">GVGAI Book Chapter 3 - Planning in GVGAI</h1><div class="content"><p><a href="https://gaigresearch.github.io/gvgaibook/">书籍网站</a><br><a href="https://gaigresearch.github.io/gvgaibook/PDF/chapters/ch03.pdf?raw=true">本章原文</a><br><a href="https://gaigresearch.github.io/gvgaibook/PDF/exercises/exercises03.pdf?raw=true">本章练习</a></p>
<hr>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><code>Planning</code>是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础，这两种方法互不相同：第一种方法从可能的游戏动作和状态种构建树，提取统计信息以决定在任何给定状态下下一步该怎么做；第二种方法一开始就定好整个计划，并使用进化计算来组合和修改它们，从而最终获得在游戏中执行的最佳选择。</p>
<p>GVGAI问题可以看作是多目标优化问题：游戏中的计分系统可能具有欺骗性，并且AI不仅需要专注于获得得分（如在传统的街机游戏中一样），而且还需要着眼于解决问题和赢得比赛，甚至还要考虑时间限制。 </p>
<h1 id="蒙特卡洛搜索树"><a href="#蒙特卡洛搜索树" class="headerlink" title="蒙特卡洛搜索树"></a>蒙特卡洛搜索树</h1><p>该算法通过一次添加单个节点来构建以不对称方式增长的搜索树，并通过使用从节点状态到游戏结束的自玩游戏来估算其游戏理论值。 书中的每个节点都会保存某些统计数据，这些统计数据表明在状态 \(s\) 下选择动作 \(a\) 时获得的奖励实验均值 \(Q(s, a)\)，从给定状态 \(s(N(s, a))\) 以及访问状态 \(s\) 的次数 \(N(s)\)。该算法通过模拟游戏中的动作，在连续的迭代中构建树，并根据这些统计信息做出选择。</p>
<p>MCTS的每个迭代都基于这几个步骤：</p>
<ul>
<li>树选择</li>
<li>扩展</li>
<li>模拟</li>
<li>后向传播 </li>
</ul>
<p><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413151308.png" alt="Figure 1"></p>
<p>刚开始，树只由根节点组成，存储了当前的游戏状态。在<strong>扩展</strong> 步骤中，如果游戏还未结束，树从根部开始搜索到一个最大深度。在这一步中，动作可以用 <em>multi-armed bandit</em>策略将其应用到前向模型中。</p>
<p><em>Multi-armed bandit</em> 策略来源于一个多臂老虎机。当摇动杆时，从一个未知的概率分布返回一个奖励 \(r\)。这个问题的目的是在按一定顺序摇动杆后最大程度减少后悔（或者最大化累计奖励）。这里后悔被定义成一个当选择到一个并非最优的杆时的机会损失。好的政策通过平衡对可用杆的探索与对过去提供更好回报的杆的利用之间的平衡来选择行动。</p>
<p>Upper Confidence Bound (UCB1)：</p>
<p>$$<br>a* = \arg \max_{a \in A(s)} \large{ Q(s, a) + C\sqrt{\frac{\ln N(s)}{N(s, a)}}\large}<br>$$</p>
<p>该函数的目标是找到一个动作 \(a\)可以使UCB1函数最大化。\(Q(s, a)\)看作是 <em>发掘*项，第二项是 *探索</em> 项。探索项与给定状态 \(s\)，每个动作 \(a\)被选择的参数\(N(s,a)\)，以及从当前状态中选取动作的数量\(N(s)\)。参数 \(C\)用于平衡发掘与探索。当\(C\) 为0时，UCB1采用贪婪策略每次都选择平均当前收益最高的动作。如果奖励 \(Q(s, a)\)被正则化到 \([0, 1]\) 之间，常用的常熟值为 \(\sqrt(2)\)。不同游戏常数值的选择可能不同。</p>
<p>在 <em>树选择</em> 步骤中，直到找到子节点少于动作数量的节点。 此时，在 <em>扩展</em> 步骤加入一个子节点，开启 <em>模拟</em> 步骤。从新节点开始，MCTS执行蒙特卡洛模拟。这时候选择一个随机的动作（均匀随机或有偏随机）一直到游戏结束（或到达一个预定义的深度）。最后，在 <em>反向传播</em> 步骤中，使用状态评估中获得的奖励，为遍历的每个节点更新统计量 \(N(s), N(s, a), Q(s, a)\)。这些步骤会循环执行，直到达到一个结束条件（例如迭代次数或者预计的时间）。</p>
<p>知道所有的迭代完成，MCTS将会推荐agent在游戏中采取的动作。该推荐策略根据存储在根节点中的统计信息来确定动作。可能推荐最近常采用的动作或者得到最高平均收益的策略，也可能直接计算公式得到返回的动作。以下时MCTS算法的伪代码。</p>
<p><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413162718.png" alt="pseudocode"></p>
<p>MCTS被认为是随时可用的算法，因为它能够在任何时刻提供有效的下一步选择。 这不同于其他算法（例如单人游戏中的A*算法，以及两人游戏中的标准“Min-Max”），这些算法通常仅在完成后才提供给下一次游玩。这使MCTS在实时领域十分合适，在实时域中，决策时间预算受到限制，从而影响了可以执行的迭代次数。</p>
<p>GVGAI也提供了基础版本的MCTS。在实际应用中，\(C\) 选取为 \(\sqrt(2)\)，且rollout深度定为10 。在模拟阶段结束时达到的每个状态都使用该时刻的游戏得分进行评估，并在比赛期间见过的最小和最大得分之间进行归一化。 如果状态为终局，则分配的奖励为较大的正数（如果游戏获胜）或负数（如果游戏输了）。 </p>
<p>虽然MCTS在GVGAI平台上的表现很好，但是没有游戏相关的知识支撑算法。Value function 仅基于得分和游戏结束状态，这些概念存在于所有游戏中，因此通常在GVGP方法中使用。 </p>
<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><p>以一个简单的游戏为例，该游戏的目的是使每次动作选取数字的累积和接近0.动作的可选范围是 <code>[-2, 2, -3, 3] * 回合数</code>。</p>
<p>首先构建 <code>State</code> 类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">class State():</span><br><span class="line">    NUM_TURNS &#x3D; 10 #最多10回合</span><br><span class="line">    GOAL &#x3D; 0 #目标是累计和为 0</span><br><span class="line">    MOVES &#x3D; [2, -2, 3, -3] # 动作可选范围</span><br><span class="line">    MAX_VALUE &#x3D; (5.0 * (NUM_TURNS - 1) * NUM_TURNS) &#x2F; 2 # 最大值为225</span><br><span class="line">    num_moves &#x3D; len(MOVES) # 动作数量</span><br><span class="line"></span><br><span class="line">    # 初始化类</span><br><span class="line">    # 累计和为0，动作为空列表，总回合数由传入参数决定</span><br><span class="line">    def __init__(self, value&#x3D;0, moves&#x3D;[], turn&#x3D;NUM_TURNS):</span><br><span class="line">        self.value &#x3D; value</span><br><span class="line">        self.moves &#x3D; moves</span><br><span class="line">        self.turn &#x3D; turn</span><br><span class="line"></span><br><span class="line">    # 下一个状态</span><br><span class="line">    # 通过当前状态得到下一状态</span><br><span class="line">    def next_state(self):</span><br><span class="line">        # 从回合数乘动作的列表中随机选择</span><br><span class="line">        nextmove &#x3D; random.choice([x * self.turn for x in self.MOVES])</span><br><span class="line">        # 更新下一个状态的成员值</span><br><span class="line">        next &#x3D; State(self.value + nextmove, self.moves + [nextmove], self.turn - 1)</span><br><span class="line">        # 返回下一个状态</span><br><span class="line">        return next</span><br><span class="line"></span><br><span class="line">    # 终结状态</span><br><span class="line">    def terminal(self):</span><br><span class="line">        # 如果剩余回合数为0</span><br><span class="line">        if self.turn &#x3D;&#x3D; 0:</span><br><span class="line">            # 结束</span><br><span class="line">            return True</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line">    # 奖励</span><br><span class="line">    def reward(self):</span><br><span class="line">        # 游戏的奖励定义为</span><br><span class="line">        # 用1减去当前值减去目标值的绝对值除以最大值</span><br><span class="line">        # 实际上就是归一化之后距离0越近奖励越多</span><br><span class="line">        r &#x3D; 1.0 - (abs(self.value - self.GOAL) &#x2F; self.MAX_VALUE)</span><br><span class="line">        return r</span><br><span class="line"></span><br><span class="line">    # 若对象在其生命周期内保持不变，而且能与其他对象相比较，那么这个对象是可哈希的</span><br><span class="line">    # 通过__hash__返回一个int值，用来标记这个对象。</span><br><span class="line">    # 这里是通过操作序列来标记两个状态是否相同</span><br><span class="line">    def __hash__(self):</span><br><span class="line">        return int(hashlib.md5(str(self.moves).encode(&#39;utf-8&#39;)).hexdigest(), 16)</span><br><span class="line"></span><br><span class="line">    # 在调用 &#96;&#x3D;&#x3D;&#96; 操作符，，实际上是调用 &#96;__eq__&#96;方法</span><br><span class="line">    def __eq__(self, other):</span><br><span class="line">        if hash(self) &#x3D;&#x3D; hash(other):</span><br><span class="line">            return True</span><br><span class="line">        else False</span><br><span class="line"></span><br><span class="line">    # __repr__主要用于调试和开发</span><br><span class="line">    # 用于打印内容</span><br><span class="line">    # repr()更能显示出对象的类型、值等信息，对象描述清晰</span><br><span class="line">    def __repr__(self):</span><br><span class="line">        s &#x3D; &quot;Value: %d; Moves: %s&quot; % (self.value, self.moves)</span><br><span class="line">        return s</span><br></pre></td></tr></table></figure>

<p>之后定义蒙特卡洛树类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">class Node():</span><br><span class="line">    def __init__(self, state, parent&#x3D;None):</span><br><span class="line">        self.visits &#x3D; 1 # 被访问次数默认为1</span><br><span class="line">        self.reward &#x3D; 0.0 # 奖励为0</span><br><span class="line">        self.state &#x3D; state # 初始状态</span><br><span class="line">        self.children &#x3D; [] # 子节点为空列表</span><br><span class="line">        self.parent &#x3D; parent # 初始父节点</span><br><span class="line"></span><br><span class="line">    # 为蒙特卡洛树增加子节点</span><br><span class="line">    def add_child(self, child_state):</span><br><span class="line">        # 直接在子节点列表里面添加一个实例，状态为子节点状态，子节点的父节点是自己</span><br><span class="line">        child&#x3D;Node(child_state, self)</span><br><span class="line">        self.children.append(child)</span><br><span class="line"></span><br><span class="line">    # 更新状态</span><br><span class="line">    def update(self, reward):</span><br><span class="line">        # 更新奖励，且访问数量加1</span><br><span class="line">        self.reward +&#x3D; reward</span><br><span class="line">        self.visits +&#x3D; 1</span><br><span class="line"></span><br><span class="line">    # 判断是否完全拓展</span><br><span class="line">    def fully_expanded(self):</span><br><span class="line">        # 如果子节点的数量已经与状态中的动作数量相等了，则已搜索完毕</span><br><span class="line">        if len(self.children) &#x3D;&#x3D; self.state.num_moves:</span><br><span class="line">            return True</span><br><span class="line">        return False</span><br><span class="line"></span><br><span class="line">    # 打印内容</span><br><span class="line">    def __repr__(self):</span><br><span class="line">        s &#x3D; &quot;Node; children: %d; visits: %d; reward: %f&quot; % (len(self.children), self.visits, self.reward)</span><br><span class="line">        return s</span><br></pre></td></tr></table></figure>

<p>在定义完基本数据结构之后，就要定义策略方法了。首先定义默认策略：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">def DEFAULTPOLICY(state):</span><br><span class="line">    # 如果还未搜索结束</span><br><span class="line">    while state.terminal() &#x3D;&#x3D; False:</span><br><span class="line">        # 则继续搜索 找到下一个状态</span><br><span class="line">        state &#x3D; state.next_state()</span><br><span class="line">    # 返回奖励值</span><br><span class="line">    return state.reward()</span><br><span class="line"></span><br><span class="line">def EXPAND(node):</span><br><span class="line">    # 首先先找出已经搜索过的子节点，保存下来</span><br><span class="line">    tried_children &#x3D; [c.state for c in node.children]</span><br><span class="line">    # 找到该状态的下一个状态</span><br><span class="line">    new_state &#x3D; node.state.next_state()</span><br><span class="line">    # 循环验证，若该状态已被尝试</span><br><span class="line">    while new_state in tried_children:</span><br><span class="line">        # 再增加一个新状态，直到没有重复</span><br><span class="line">        new_state &#x3D; node.state.next_state()</span><br><span class="line">    # 将新状态加入子节点</span><br><span class="line">    node.add_child(new_state)</span><br><span class="line">    # 返回最后一个节点</span><br><span class="line">    return node.children[-1]</span><br><span class="line"></span><br><span class="line">def TREEPOLICY(node):</span><br><span class="line">    # 如果有多种选择时且你不想要完全扩展时的一个强制“发掘“的奇技淫巧</span><br><span class="line"></span><br><span class="line">    # 在还未完结 时</span><br><span class="line">    while node.state.terminal() &#x3D;&#x3D; False:</span><br><span class="line">        # 如果子节点数量为0</span><br><span class="line">        if len(node.children) &#x3D;&#x3D; 0:</span><br><span class="line">            # 扩展</span><br><span class="line">            return EXPAND(node)</span><br><span class="line">        # 随机，二分之一概率</span><br><span class="line">        elif random.uniform(0, 1) &lt; 0.5:</span><br><span class="line">            # 找到最佳子节点</span><br><span class="line">            node &#x3D; BESTCHILD(node, SCALAR)</span><br><span class="line">        # 否则</span><br><span class="line">        else:</span><br><span class="line">            # 如果还未完全扩展</span><br><span class="line">            if node.fully_expanded() &#x3D;&#x3D; False:</span><br><span class="line">                # 扩展</span><br><span class="line">                return EXPAND(node)</span><br><span class="line">            # 否则返回最佳子节点</span><br><span class="line">            else:</span><br><span class="line">                node &#x3D; BESTCHILD(node, SCALAR)</span><br><span class="line">    return node</span><br><span class="line"></span><br><span class="line">def BESTCHILD(node, scalar):</span><br><span class="line">    # 最高分初始为0</span><br><span class="line">    bestscore &#x3D; 0.0</span><br><span class="line">    # 最佳子节点列表为空</span><br><span class="line">    bestchildren &#x3D; []</span><br><span class="line">    # 遍历所有的子节点</span><br><span class="line">    for c in node.children:</span><br><span class="line">        # 根据公式计算</span><br><span class="line">        # 发掘项</span><br><span class="line">        exploit &#x3D; c.reward &#x2F; c.visits</span><br><span class="line">        # 探索项</span><br><span class="line">        explore &#x3D; math.sqrt(2.0 * math.log(node.visits) &#x2F; float(c.visits))</span><br><span class="line">        # UCB1总分为两者之和</span><br><span class="line">        score &#x3D; exploit + scalar * explore</span><br><span class="line"></span><br><span class="line">        # 找到最高分</span><br><span class="line">        if score &#x3D;&#x3D; bestscore:</span><br><span class="line">            bestchildren.append(c)</span><br><span class="line">        if score &gt; bestscore:</span><br><span class="line">            bestchildren &#x3D; [c]</span><br><span class="line">            bestscore &#x3D; score</span><br><span class="line"></span><br><span class="line">    # 如果最佳子节点数量为0，则报错</span><br><span class="line">    if len(bestchildren) &#x3D;&#x3D; 0:</span><br><span class="line">        logger.warn(&quot;OOPs: no best child found, probably fatal&quot;)</span><br><span class="line">    # 随即返回一个最佳子节点</span><br><span class="line">    return random.choice(bestchildren)</span><br><span class="line"></span><br><span class="line"># 复制树</span><br><span class="line">def BACKUP(node,reward):</span><br><span class="line">	while node!&#x3D;None:</span><br><span class="line">		node.visits+&#x3D;1</span><br><span class="line">		node.reward+&#x3D;reward</span><br><span class="line">		node&#x3D;node.parent</span><br><span class="line">	return</span><br></pre></td></tr></table></figure>

<p>总搜索函数为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 输入耗费预算和根节点</span><br><span class="line">def UCTSEARCH(budget, root):</span><br><span class="line">    # 在预算范围内循环</span><br><span class="line">    for iter in range(int(budget)):</span><br><span class="line">        # 每10000次打印一次</span><br><span class="line">        if iter%10000 &#x3D;&#x3D; 9999:</span><br><span class="line">            logger.info(&quot;simulation: %d&quot; %iter)</span><br><span class="line">            logger.info(root)</span><br><span class="line"></span><br><span class="line">            # 通过TreePolicy找到最佳子节点</span><br><span class="line">            front &#x3D; TREEPOLICY(root)</span><br><span class="line">            # 得到奖励</span><br><span class="line">            reward &#x3D; DEFAULTPOLICY(front.state)</span><br><span class="line">            # 备份搜索树</span><br><span class="line">            BACKUP(front, reward)</span><br><span class="line">    # 返回最佳策略</span><br><span class="line">    return BESTCHILD(root, 0)</span><br></pre></td></tr></table></figure>

<p>那么一个完整的执行过程写在 <code>main</code> 函数中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:</span><br><span class="line">    parser &#x3D; argparse.ArgumentParser(description&#x3D;&#39;MCTS research code&#39;)</span><br><span class="line">    # 模拟预算参数</span><br><span class="line">    parser.add_argument(&#39;--num_sims&#39;, action&#x3D;&quot;store&quot;, required&#x3D;True, type&#x3D;int)</span><br><span class="line">    # &#96;levels&#96; 是使用MCTS挑选最佳子节点的次数 </span><br><span class="line">    parser.add_argument(&#39;--levels&#39;, action&#x3D;&quot;store&quot;, required&#x3D;True, type&#x3D;int, choices&#x3D;range(State.NUM_TURNS))</span><br><span class="line">    args &#x3D; parser.parse_args()</span><br><span class="line"></span><br><span class="line">    # 定义空树</span><br><span class="line">    current_node &#x3D; Node(State())</span><br><span class="line">    for l in range(args.levels):</span><br><span class="line">        current_node &#x3D; UCTSEARCH(args.num_sims &#x2F; (l + 1), current_node)</span><br><span class="line">        print(&quot;level %d&quot; % l)</span><br><span class="line">        print(&quot;Num Children: %d&quot; % len(current_node.children))</span><br><span class="line">        for i, c in enumerate(current_node.children):</span><br><span class="line">            print(i, c)</span><br><span class="line">        print(&quot;Best Child: %s&quot; % current_node.state)</span><br><span class="line"></span><br><span class="line">        print(&quot;--------------------------------&quot;)</span><br></pre></td></tr></table></figure>

<p>若 <code>num_sims</code> 为 <code>100000</code>，深度 <code>levels</code> 为 <code>9</code>，一次模拟结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">level 0</span><br><span class="line">Num Children: 2</span><br><span class="line">0 Node; children: 0; visits: 2; reward: 0.928889</span><br><span class="line">1 Node; children: 0; visits: 2; reward: 0.920000</span><br><span class="line">Best Child: Value: -30; Moves: [-30]</span><br><span class="line">--------------------------------</span><br><span class="line">level 1</span><br><span class="line">Num Children: 1</span><br><span class="line">0 Node; children: 0; visits: 2; reward: 0.911111</span><br><span class="line">Best Child: Value: -3; Moves: [-30, 27]</span><br><span class="line">--------------------------------</span><br><span class="line">level 2</span><br><span class="line">Num Children: 1</span><br><span class="line">0 Node; children: 0; visits: 2; reward: 0.813333</span><br><span class="line">Best Child: Value: -27; Moves: [-30, 27, -24]</span><br><span class="line">--------------------------------</span><br><span class="line">level 3</span><br><span class="line">Num Children: 1</span><br><span class="line">0 Node; children: 0; visits: 2; reward: 0.826667</span><br><span class="line">Best Child: Value: -48; Moves: [-30, 27, -24, -21]</span><br><span class="line">--------------------------------</span><br><span class="line">level 4</span><br><span class="line">Num Children: 2</span><br><span class="line">0 Node; children: 0; visits: 2; reward: 0.848889</span><br><span class="line">1 Node; children: 0; visits: 2; reward: 0.764444</span><br><span class="line">Best Child: Value: -30; Moves: [-30, 27, -24, -21, 18]</span><br><span class="line">--------------------------------</span><br><span class="line">level 5</span><br><span class="line">Num Children: 0</span><br><span class="line">Best Child: Value: -20; Moves: [-30, 27, -24, -21, 18, 10]</span><br><span class="line">--------------------------------</span><br><span class="line">level 6</span><br><span class="line">Num Children: 0</span><br><span class="line">Best Child: Value: -12; Moves: [-30, 27, -24, -21, 18, 10, 8]</span><br><span class="line">--------------------------------</span><br><span class="line">level 7</span><br><span class="line">Num Children: 0</span><br><span class="line">Best Child: Value: -6; Moves: [-30, 27, -24, -21, 18, 10, 8, 6]</span><br><span class="line">--------------------------------</span><br><span class="line">level 8</span><br><span class="line">Num Children: 0</span><br><span class="line">Best Child: Value: -12; Moves: [-30, 27, -24, -21, 18, 10, 8, 6, -6]</span><br><span class="line">--------------------------------</span><br></pre></td></tr></table></figure>

<h1 id="基于知识的快速进化MCTS"><a href="#基于知识的快速进化MCTS" class="headerlink" title="基于知识的快速进化MCTS"></a>基于知识的快速进化MCTS</h1></div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/GVGAI-AI/">GVGAI; AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5ee823fc1d4c470012df72c5&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20200616095101.jpg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/rasin" style="background-color:rgba(255,128,62,.87);border-color:transparent;color:white;" target="_blank" rel="noopener"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20200616095122.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/04/11/VGDL%E8%8C%83%E4%BE%8B%E8%A7%A3%E8%AF%BB/"><span class="level-item">VGDL范例解读</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://rasin.me/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/';
            this.page.identifier = '2021/04/12/GVGAI Book Chapter 3 - Planning in GVGAI/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'rasinme' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="" src="/img/avatar.png" alt="Rasin Gue"></figure><p class="title is-size-4 is-block line-height-inherit">Rasin Gue</p><p class="is-size-6 is-block">PhD in Progress</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Tsukuba, Japan</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">5</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/RasinGue" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/RasinGue"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/mizumori_setsu"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/rasin"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2021-04-12T10:35:55.000Z">2021-04-12</time></p><p class="title is-6"><a class="link-muted" href="/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/">GVGAI Book Chapter 3 - Planning in GVGAI</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-04-11T19:35:55.000Z">2021-04-11</time></p><p class="title is-6"><a class="link-muted" href="/2021/04/11/VGDL%E8%8C%83%E4%BE%8B%E8%A7%A3%E8%AF%BB/">VGDL范例解读</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-04-10T19:35:55.000Z">2021-04-10</time></p><p class="title is-6"><a class="link-muted" href="/2021/04/10/GVGAI%20Book%20Chapter%202%20-%20VGDL%20and%20the%20GVGAI%20Framework%20--%20Exercises/">GVGAI Book Chapter 2 - VGDL and the GVGAI Framework -- Exercises</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-03-23T19:35:55.000Z">2021-03-23</time></p><p class="title is-6"><a class="link-muted" href="/2021/03/23/%E9%87%8D%E8%BF%94Gamemaker%20Studio2/">重返Gamemaker Studio 入门篇2</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-02-23T19:35:55.000Z">2021-02-23</time></p><p class="title is-6"><a class="link-muted" href="/2021/02/23/%E9%87%8D%E8%BF%94Gamemaker%20Studio1/">重返Gamemaker Studio 入门篇1</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2021/04/"><span class="level-start"><span class="level-item">四月 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/03/"><span class="level-start"><span class="level-item">三月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/02/"><span class="level-start"><span class="level-item">二月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">六月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/GVGAI-AI/"><span class="tag">GVGAI; AI</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GVGAI-VGDL/"><span class="tag">GVGAI; VGDL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gamemaker-Studio/"><span class="tag">Gamemaker Studio</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VGDL/"><span class="tag">VGDL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/joural/"><span class="tag">joural</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Rasin&#039;s Blog" height="28"></a><p class="size-small"><span>&copy; 2021 Rasin Gue</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://rasin.me',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>