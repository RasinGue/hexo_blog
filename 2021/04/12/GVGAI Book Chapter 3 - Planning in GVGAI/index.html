<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>GVGAI Book Chapter 3 - Planning in GVGAI - Rasin&#039;s Blog</title><meta description="书籍网站本章原文本章练习  简介Planning是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础"><meta property="og:type" content="blog"><meta property="og:title" content="GVGAI Book Chapter 3 - Planning in GVGAI"><meta property="og:url" content="https://rasin.me/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/"><meta property="og:site_name" content="Scienage Mafelteens"><meta property="og:description" content="书籍网站本章原文本章练习  简介Planning是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413151308.png"><meta property="og:image" content="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413162718.png"><meta property="og:image" content="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210416172138.png"><meta property="article:published_time" content="2021-04-12T10:35:55.000Z"><meta property="article:modified_time" content="2021-04-18T01:28:27.153Z"><meta property="article:author" content="Rasin Gue"><meta property="article:tag" content="GVGAI; AI"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413151308.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://rasin.me/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/"},"headline":"Rasin's Blog","image":["https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413151308.png","https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413162718.png","https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210416172138.png"],"datePublished":"2021-04-12T10:35:55.000Z","dateModified":"2021-04-18T01:28:27.153Z","author":{"@type":"Person","name":"Rasin Gue"},"description":"书籍网站本章原文本章练习  简介Planning是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础"}</script><link rel="canonical" href="https://rasin.me/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-166789681-2" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-166789681-2');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Rasin&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2021-04-12T10:35:55.000Z" title="2021-04-12T10:35:55.000Z">2021-04-12</time><span class="level-item">30 分钟 读完 (大约 4458 个字)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">GVGAI Book Chapter 3 - Planning in GVGAI</h1><div class="content"><p><a href="https://gaigresearch.github.io/gvgaibook/">书籍网站</a><br><a href="https://gaigresearch.github.io/gvgaibook/PDF/chapters/ch03.pdf?raw=true">本章原文</a><br><a href="https://gaigresearch.github.io/gvgaibook/PDF/exercises/exercises03.pdf?raw=true">本章练习</a></p>
<hr>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p><code>Planning</code>是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础，这两种方法互不相同：第一种方法从可能的游戏动作和状态种构建树，提取统计信息以决定在任何给定状态下下一步该怎么做；第二种方法一开始就定好整个计划，并使用进化计算来组合和修改它们，从而最终获得在游戏中执行的最佳选择。</p>
<p>GVGAI问题可以看作是多目标优化问题：游戏中的计分系统可能具有欺骗性，并且AI不仅需要专注于获得得分（如在传统的街机游戏中一样），而且还需要着眼于解决问题和赢得比赛，甚至还要考虑时间限制。 </p>
<h1 id="蒙特卡洛搜索树"><a href="#蒙特卡洛搜索树" class="headerlink" title="蒙特卡洛搜索树"></a>蒙特卡洛搜索树</h1><p>该算法通过一次添加单个节点来构建以不对称方式增长的搜索树，并通过使用从节点状态到游戏结束的自玩游戏来估算其游戏理论值。 书中的每个节点都会保存某些统计数据，这些统计数据表明在状态 \(s\) 下选择动作 \(a\) 时获得的奖励实验均值 \(Q(s, a)\)，从给定状态 \(s(N(s, a))\) 以及访问状态 \(s\) 的次数 \(N(s)\)。该算法通过模拟游戏中的动作，在连续的迭代中构建树，并根据这些统计信息做出选择。</p>
<p>MCTS的每个迭代都基于这几个步骤：</p>
<ul>
<li>树选择</li>
<li>扩展</li>
<li>模拟</li>
<li>后向传播 </li>
</ul>
<p><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413151308.png" alt="Figure 1"></p>
<p>刚开始，树只由根节点组成，存储了当前的游戏状态。在<strong>扩展</strong> 步骤中，如果游戏还未结束，树从根部开始搜索到一个最大深度。在这一步中，动作可以用 <em>multi-armed bandit</em>策略将其应用到前向模型中。</p>
<p><em>Multi-armed bandit</em> 策略来源于一个多臂老虎机。当摇动杆时，从一个未知的概率分布返回一个奖励 \(r\)。这个问题的目的是在按一定顺序摇动杆后最大程度减少后悔（或者最大化累计奖励）。这里后悔被定义成一个当选择到一个并非最优的杆时的机会损失。好的政策通过平衡对可用杆的探索与对过去提供更好回报的杆的利用之间的平衡来选择行动。</p>
<p>Upper Confidence Bound (UCB1)：</p>
<p>$$<br>a* = \underset{a\ \in \ A( s)}{\mathrm{argmax}} \ \Bigl{Q( s,\ a) \ +\ C\sqrt{\frac{\ln N( s)}{N( s,a)}}\Bigr}<br>$$</p>
<p>该函数的目标是找到一个动作 \(a\)可以使UCB1函数最大化。\(Q(s, a)\)看作是 <em>发掘*项，第二项是 *探索</em> 项。探索项与给定状态 \(s\)，每个动作 \(a\)被选择的参数\(N(s,a)\)，以及从当前状态中选取动作的数量\(N(s)\)。参数 \(C\)用于平衡发掘与探索。当\(C\) 为0时，UCB1采用贪婪策略每次都选择平均当前收益最高的动作。如果奖励 \(Q(s, a)\)被正则化到 \([0, 1]\) 之间，常用的常数值为 \(\sqrt{2}\)。不同游戏常数值的选择可能不同。</p>
<p>在 <em>树选择</em> 步骤中，直到找到子节点少于动作数量的节点。 此时，在 <em>扩展</em> 步骤加入一个子节点，开启 <em>模拟</em> 步骤。从新节点开始，MCTS执行蒙特卡洛模拟。这时候选择一个随机的动作（均匀随机或有偏随机）一直到游戏结束（或到达一个预定义的深度）。最后，在 <em>反向传播</em> 步骤中，使用状态评估中获得的奖励，为遍历的每个节点更新统计量 \(N(s), N(s, a), Q(s, a)\)。这些步骤会循环执行，直到达到一个结束条件（例如迭代次数或者预计的时间）。</p>
<p>直到所有的迭代完成，MCTS将会推荐agent在游戏中采取的动作。该推荐策略根据存储在根节点中的统计信息来确定动作。可能推荐最近常采用的动作或者得到最高平均收益的策略，也可能直接计算公式得到返回的动作。以下为MCTS算法的伪代码：</p>
<p><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210413162718.png" alt="pseudocode"></p>
<p>MCTS被认为是随时可用的算法，因为它能够在任何时刻提供有效的下一步选择。 这不同于其他算法（例如单人游戏中的A*算法，以及两人游戏中的标准“Min-Max”），这些算法通常仅在完成后才提供给下一次游玩。这使MCTS在实时领域十分合适，在实时域中，决策时间预算受到限制，从而影响了可以执行的迭代次数。</p>
<p>GVGAI也提供了基础版本的MCTS。在实际应用中，\(C\) 选取为 \(\sqrt{2})\)，且rollout深度定为10 。在模拟阶段结束时达到的每个状态都使用该时刻的游戏得分进行评估，并在比赛期间见过的最小和最大得分之间进行归一化。 如果状态为终局，则分配的奖励为较大的正数（如果游戏获胜）或负数（如果游戏输了）。 </p>
<p>虽然MCTS在GVGAI平台上的表现很好，但是没有游戏相关的知识支撑算法。Value function 仅基于得分和游戏结束状态，这些概念存在于所有游戏中，因此通常在GVGP方法中使用。 </p>
<h2 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h2><p>以一个简单的游戏为例，该游戏的目的是使每次动作选取数字的累积和接近0.动作的可选范围是 <code>[-2, 2, -3, 3] * 回合数</code>。</p>
<p>首先构建 <code>State</code> 类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs plain">class State():<br>    NUM_TURNS &#x3D; 10 #最多10回合<br>    GOAL &#x3D; 0 #目标是累计和为 0<br>    MOVES &#x3D; [2, -2, 3, -3] # 动作可选范围<br>    MAX_VALUE &#x3D; (5.0 * (NUM_TURNS - 1) * NUM_TURNS) &#x2F; 2 # 最大值为225<br>    num_moves &#x3D; len(MOVES) # 动作数量<br><br>    # 初始化类<br>    # 累计和为0，动作为空列表，总回合数由传入参数决定<br>    def __init__(self, value&#x3D;0, moves&#x3D;[], turn&#x3D;NUM_TURNS):<br>        self.value &#x3D; value<br>        self.moves &#x3D; moves<br>        self.turn &#x3D; turn<br><br>    # 下一个状态<br>    # 通过当前状态得到下一状态<br>    def next_state(self):<br>        # 从回合数乘动作的列表中随机选择<br>        nextmove &#x3D; random.choice([x * self.turn for x in self.MOVES])<br>        # 更新下一个状态的成员值<br>        next &#x3D; State(self.value + nextmove, self.moves + [nextmove], self.turn - 1)<br>        # 返回下一个状态<br>        return next<br><br>    # 终结状态<br>    def terminal(self):<br>        # 如果剩余回合数为0<br>        if self.turn &#x3D;&#x3D; 0:<br>            # 结束<br>            return True<br>        return False<br><br>    # 奖励<br>    def reward(self):<br>        # 游戏的奖励定义为<br>        # 用1减去当前值减去目标值的绝对值除以最大值<br>        # 实际上就是归一化之后距离0越近奖励越多<br>        r &#x3D; 1.0 - (abs(self.value - self.GOAL) &#x2F; self.MAX_VALUE)<br>        return r<br><br>    # 若对象在其生命周期内保持不变，而且能与其他对象相比较，那么这个对象是可哈希的<br>    # 通过__hash__返回一个int值，用来标记这个对象。<br>    # 这里是通过操作序列来标记两个状态是否相同<br>    def __hash__(self):<br>        return int(hashlib.md5(str(self.moves).encode(&#39;utf-8&#39;)).hexdigest(), 16)<br><br>    # 在调用 &#96;&#x3D;&#x3D;&#96; 操作符，，实际上是调用 &#96;__eq__&#96;方法<br>    def __eq__(self, other):<br>        if hash(self) &#x3D;&#x3D; hash(other):<br>            return True<br>        else False<br><br>    # __repr__主要用于调试和开发<br>    # 用于打印内容<br>    # repr()更能显示出对象的类型、值等信息，对象描述清晰<br>    def __repr__(self):<br>        s &#x3D; &quot;Value: %d; Moves: %s&quot; % (self.value, self.moves)<br>        return s<br></code></pre></td></tr></table></figure>

<p>之后定义蒙特卡洛树类：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs plain">class Node():<br>    def __init__(self, state, parent&#x3D;None):<br>        self.visits &#x3D; 1 # 被访问次数默认为1<br>        self.reward &#x3D; 0.0 # 奖励为0<br>        self.state &#x3D; state # 初始状态<br>        self.children &#x3D; [] # 子节点为空列表<br>        self.parent &#x3D; parent # 初始父节点<br><br>    # 为蒙特卡洛树增加子节点<br>    def add_child(self, child_state):<br>        # 直接在子节点列表里面添加一个实例，状态为子节点状态，子节点的父节点是自己<br>        child&#x3D;Node(child_state, self)<br>        self.children.append(child)<br><br>    # 更新状态<br>    def update(self, reward):<br>        # 更新奖励，且访问数量加1<br>        self.reward +&#x3D; reward<br>        self.visits +&#x3D; 1<br><br>    # 判断是否完全拓展<br>    def fully_expanded(self):<br>        # 如果子节点的数量已经与状态中的动作数量相等了，则已搜索完毕<br>        if len(self.children) &#x3D;&#x3D; self.state.num_moves:<br>            return True<br>        return False<br><br>    # 打印内容<br>    def __repr__(self):<br>        s &#x3D; &quot;Node; children: %d; visits: %d; reward: %f&quot; % (len(self.children), self.visits, self.reward)<br>        return s<br></code></pre></td></tr></table></figure>

<p>在定义完基本数据结构之后，就要定义策略方法了。首先定义默认策略：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs plain">def DEFAULTPOLICY(state):<br>    # 如果还未搜索结束<br>    while state.terminal() &#x3D;&#x3D; False:<br>        # 则继续搜索 找到下一个状态<br>        state &#x3D; state.next_state()<br>    # 返回奖励值<br>    return state.reward()<br><br>def EXPAND(node):<br>    # 首先先找出已经搜索过的子节点，保存下来<br>    tried_children &#x3D; [c.state for c in node.children]<br>    # 找到该状态的下一个状态<br>    new_state &#x3D; node.state.next_state()<br>    # 循环验证，若该状态已被尝试<br>    while new_state in tried_children:<br>        # 再增加一个新状态，直到没有重复<br>        new_state &#x3D; node.state.next_state()<br>    # 将新状态加入子节点<br>    node.add_child(new_state)<br>    # 返回最后一个节点<br>    return node.children[-1]<br><br>def TREEPOLICY(node):<br>    # 如果有多种选择时且你不想要完全扩展时的一个强制“发掘“的奇技淫巧<br><br>    # 在还未完结 时<br>    while node.state.terminal() &#x3D;&#x3D; False:<br>        # 如果子节点数量为0<br>        if len(node.children) &#x3D;&#x3D; 0:<br>            # 扩展<br>            return EXPAND(node)<br>        # 随机，二分之一概率<br>        elif random.uniform(0, 1) &lt; 0.5:<br>            # 找到最佳子节点<br>            node &#x3D; BESTCHILD(node, SCALAR)<br>        # 否则<br>        else:<br>            # 如果还未完全扩展<br>            if node.fully_expanded() &#x3D;&#x3D; False:<br>                # 扩展<br>                return EXPAND(node)<br>            # 否则返回最佳子节点<br>            else:<br>                node &#x3D; BESTCHILD(node, SCALAR)<br>    return node<br><br>def BESTCHILD(node, scalar):<br>    # 最高分初始为0<br>    bestscore &#x3D; 0.0<br>    # 最佳子节点列表为空<br>    bestchildren &#x3D; []<br>    # 遍历所有的子节点<br>    for c in node.children:<br>        # 根据公式计算<br>        # 发掘项<br>        exploit &#x3D; c.reward &#x2F; c.visits<br>        # 探索项<br>        explore &#x3D; math.sqrt(2.0 * math.log(node.visits) &#x2F; float(c.visits))<br>        # UCB1总分为两者之和<br>        score &#x3D; exploit + scalar * explore<br><br>        # 找到最高分<br>        if score &#x3D;&#x3D; bestscore:<br>            bestchildren.append(c)<br>        if score &gt; bestscore:<br>            bestchildren &#x3D; [c]<br>            bestscore &#x3D; score<br><br>    # 如果最佳子节点数量为0，则报错<br>    if len(bestchildren) &#x3D;&#x3D; 0:<br>        logger.warn(&quot;OOPs: no best child found, probably fatal&quot;)<br>    # 随即返回一个最佳子节点<br>    return random.choice(bestchildren)<br><br># 反向传播<br>def BACKUP(node,reward):<br>	while node!&#x3D;None:<br>		node.visits+&#x3D;1<br>		node.reward+&#x3D;reward<br>		node&#x3D;node.parent<br>	return<br></code></pre></td></tr></table></figure>

<p>总搜索函数为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs plain"># 输入耗费预算和根节点<br>def UCTSEARCH(budget, root):<br>    # 在预算范围内循环<br>    for iter in range(int(budget)):<br>        # 每10000次打印一次<br>        if iter%10000 &#x3D;&#x3D; 9999:<br>            logger.info(&quot;simulation: %d&quot; %iter)<br>            logger.info(root)<br><br>            # 通过TreePolicy找到最佳子节点<br>            front &#x3D; TREEPOLICY(root)<br>            # 得到奖励<br>            reward &#x3D; DEFAULTPOLICY(front.state)<br>            # 反向传播<br>            BACKUP(front, reward)<br>    # 返回最佳策略<br>    return BESTCHILD(root, 0)<br></code></pre></td></tr></table></figure>

<p>那么一个完整的执行过程写在 <code>main</code> 函数中：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs plain">if __name__ &#x3D;&#x3D; &#39;__main__&#39;:<br>    parser &#x3D; argparse.ArgumentParser(description&#x3D;&#39;MCTS research code&#39;)<br>    # 模拟预算参数<br>    parser.add_argument(&#39;--num_sims&#39;, action&#x3D;&quot;store&quot;, required&#x3D;True, type&#x3D;int)<br>    # &#96;levels&#96; 是使用MCTS挑选最佳子节点的次数 <br>    parser.add_argument(&#39;--levels&#39;, action&#x3D;&quot;store&quot;, required&#x3D;True, type&#x3D;int, choices&#x3D;range(State.NUM_TURNS))<br>    args &#x3D; parser.parse_args()<br><br>    # 定义空树<br>    current_node &#x3D; Node(State())<br>    for l in range(args.levels):<br>        current_node &#x3D; UCTSEARCH(args.num_sims &#x2F; (l + 1), current_node)<br>        print(&quot;level %d&quot; % l)<br>        print(&quot;Num Children: %d&quot; % len(current_node.children))<br>        for i, c in enumerate(current_node.children):<br>            print(i, c)<br>        print(&quot;Best Child: %s&quot; % current_node.state)<br><br>        print(&quot;--------------------------------&quot;)<br></code></pre></td></tr></table></figure>

<p>若 <code>num_sims</code> 为 <code>100000</code>，深度 <code>levels</code> 为 <code>9</code>，一次模拟结果为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs plain">level 0<br>Num Children: 2<br>0 Node; children: 0; visits: 2; reward: 0.928889<br>1 Node; children: 0; visits: 2; reward: 0.920000<br>Best Child: Value: -30; Moves: [-30]<br>--------------------------------<br>level 1<br>Num Children: 1<br>0 Node; children: 0; visits: 2; reward: 0.911111<br>Best Child: Value: -3; Moves: [-30, 27]<br>--------------------------------<br>level 2<br>Num Children: 1<br>0 Node; children: 0; visits: 2; reward: 0.813333<br>Best Child: Value: -27; Moves: [-30, 27, -24]<br>--------------------------------<br>level 3<br>Num Children: 1<br>0 Node; children: 0; visits: 2; reward: 0.826667<br>Best Child: Value: -48; Moves: [-30, 27, -24, -21]<br>--------------------------------<br>level 4<br>Num Children: 2<br>0 Node; children: 0; visits: 2; reward: 0.848889<br>1 Node; children: 0; visits: 2; reward: 0.764444<br>Best Child: Value: -30; Moves: [-30, 27, -24, -21, 18]<br>--------------------------------<br>level 5<br>Num Children: 0<br>Best Child: Value: -20; Moves: [-30, 27, -24, -21, 18, 10]<br>--------------------------------<br>level 6<br>Num Children: 0<br>Best Child: Value: -12; Moves: [-30, 27, -24, -21, 18, 10, 8]<br>--------------------------------<br>level 7<br>Num Children: 0<br>Best Child: Value: -6; Moves: [-30, 27, -24, -21, 18, 10, 8, 6]<br>--------------------------------<br>level 8<br>Num Children: 0<br>Best Child: Value: -12; Moves: [-30, 27, -24, -21, 18, 10, 8, 6, -6]<br>--------------------------------<br></code></pre></td></tr></table></figure>

<h1 id="基于知识的快速进化MCTS"><a href="#基于知识的快速进化MCTS" class="headerlink" title="基于知识的快速进化MCTS"></a>基于知识的快速进化MCTS</h1><h2 id="MCTS中的快速进化"><a href="#MCTS中的快速进化" class="headerlink" title="MCTS中的快速进化"></a>MCTS中的快速进化</h2><p><code>KB Fast-Evo MCTS</code> 使用进化算法从环境中来学习<code>rollout polic</code>。该算法使用进化方法来调整一系列权重 \(w\)对蒙特卡洛模拟进行偏移。这些权重可用于结合针对当前游戏状态提取的一组固定功能来选择每个步骤的动作。</p>
<p>每一次 <code>rollout</code> 均使用最后到达的状态值作为适应性对单组权重进行评价。使用到的进化权重的算法为 (1+1)进化策略。该策略的伪代码如下：</p>
<p><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20210416172138.png" alt="Algorithm 2"></p>
<p>第三行的调用检索了下一个个体来评估 <code>(w)</code>， <code>a</code> 和适应值在第八行给定。权重 <code>w</code>的向量用于便宜 <code>rollout</code>（第六行）。对于每个在 <code>rollout</code> 中找到的状态，首先 <code>N</code> 个数量的特征被提取（从状态空间\(S\)到特征空间\(F\)）。给定可行的动作 <code>A</code>，特征的权重和值制定了每个动作的相对强度 \((a_i)\)，如下列公式所示：</p>
<p>$$<br>a_i = \sum_{j=1}^N w_{ij} \times f_i<br>$$</p>
<p>这些动作都是经过特征加权过的动作，权重都存在矩阵 \(W\) 中，每一项 \(w_{ij}\) 代表对动作\(i\)经过特征 \(j\) 的权重。最后用一个softmax函数来选择蒙特卡罗模拟：</p>
<p>$$<br>P(a_i) = \frac{e^{-a_i}}{\sum^{A}_{j=1} e^{-a_j}}<br>$$</p>
<p>实际上，这些特征取决于游戏中特定精灵贴图的存在和消失，N特征的数量不仅每个游戏中不同，可能每个步骤中都不同。因此，该算法对于每个步骤中特征数量的加权需要更加灵活。</p>
<h2 id="学习领域知识"><a href="#学习领域知识" class="headerlink" title="学习领域知识"></a>学习领域知识</h2><p>定义 <code>KB Fast-Evo MCTS</code> 的下一步便是增加一个可以提供更强力的你和函数系统来使得个体进化。你和实在rollout结束的时候计算的，目标是顶一个一个状态估计函数，这个函数的知识是在玩游戏的时候 <em>动态学习</em>的。</p>
<p>为了构建这个函数，<em>知识库<em>可以被分解为两个部分：</em>好奇心</em> + <em>经验<em>。</em>好奇心<em>指的是去发现与其他精灵贴图碰撞时产生的效果，</em>经验</em> 权衡那些能够提供分数增长的事件。事件记录可能是主角再碰到其他对象或者产生一些其他精灵贴图后提取的（如NPC，资源，非静态对象和传送门等）。每个 <em>知识项</em> 包含了以下统计数据：</p>
<ul>
<li>\(Z_i\): 事件 \(i\) 发生的概率</li>
<li>\(\bar{x_i}\): 分数的变化的平均值，即事件发生前后游戏分数之间的变化。多个事件在同一个游戏时间片中发生，可能无法确定哪个事件出发了得分变化。因此，事件发生概率 \(Z_i\)越大，分数变化平均值 \(\bar{x_i}\)就越准确。</li>
</ul>
<p>这两个值在蒙特卡洛模拟的每次前向模型调用时更新。当达到<code>rollout</code>结束时的状态，下面的值将被计算：</p>
<ul>
<li>分数变化 \(\triangle R\): 初始状态和结束状态之间的游戏分数变化</li>
<li>好奇心：知识改变 \(\triangle Z = \sum_{i=1}^N \triangle (K_i)\)用于测量知识库中对于每个知识项\(i\)，所有 \(Z_i\) 的变化。\(\triangle (K_i)\) 由下列公式计算，其中 \(Z_{i0}\)是 \(Z_i\) 的初始值，\(Z_{iF}\) 是\(Z_i\)的最终值。当 <code>rollouts</code> 产生更多事件时，\(\triangle Z\) 会更高。如果某个事件非常稀有，则会提供较高的 \(\triangle Z\) 值，有利于模拟中的知识收集。：</li>
</ul>
<p>$$<br>\triangle (K_i) = \begin{cases} Z_{iF} &amp; Z_{i0} =0\ \frac{Z_{iF}}{Z_{i0}} -1 &amp; otherwise<br>\end{cases}<br>$$</p>
<ul>
<li>经验： \(\triangle D = \sum_{i=1}^{N} \triangle (D_i)\) 经验是一种从 <code>rollout</code> 开始到结束到每个类型为 \(i\) 精灵贴图的距离变化的度量。以下函数定义了 \(\triangle (D_i) \)，其中 \(D_{i0}\) 是 <code>rollout</code> 开始时到最接近类型 \(i\) 精灵贴图的距离，\(D_{if}\) 是 <code>rollout</code> 结束时的距离。如果玩家在 <code>rollout</code> 期间与那些已知精灵贴图减少了 \(\bar{x_i}\) 的距离而不是那些未知贴图的距离，那么 \(\triangle D\) 就会变得更高。</li>
</ul>
<p>$$<br>\triangle (D_i) = \begin{cases}<br>1-\frac{D_{iF}}{D_{i0}} &amp; Z_{i0} =0\ or\ \left( D_{i0} \  &gt;0\ and\ \overline{x_{i}}  &gt;0\right)\<br>0 &amp; otherwise<br>\end{cases}<br>$$</p>
<p>下列函数表示了游戏状态的最终值以及对于评估个体的拟合。这个值称为 \(\delta R \)，除非 \(\triangle R =0 \)。当其为0时，<code>rollout</code> 中的所有的动作都无法改变游戏分数。下列函数以 \(\alpha = 0.66\) 和 \(\beta = 0.33\) 为参数定义了一个线性函数：</p>
<p>$$<br>Reward = \begin{cases}<br>\triangle R &amp; \triangle R\neq 0\<br>\alpha \triangleserifs Z\ +\ \beta \triangle D &amp; otherwise<br>\end{cases}<br>$$</p>
<p>因此，新的值函数将优先权分配给产生得分增加的动作。但如果没有分数增加的话，则把优先权分配给提供给知识库更多信息或者使玩家更接近提供分数精灵贴图的动作。</p>
</div><div class="article-tags size-small is-uppercase mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/GVGAI-AI/">GVGAI; AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=5ee823fc1d4c470012df72c5&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20200616095101.jpg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/rasin" style="background-color:rgba(255,128,62,.87);border-color:transparent;color:white;" target="_blank" rel="noopener"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://raw.githubusercontent.com/rasin-tsukuba/blog-images/master/img/20200616095122.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/04/11/VGDL%E8%8C%83%E4%BE%8B%E8%A7%A3%E8%AF%BB/"><span class="level-item">VGDL范例解读</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://rasin.me/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/';
            this.page.identifier = '2021/04/12/GVGAI Book Chapter 3 - Planning in GVGAI/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'rasinme' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="" src="/img/avatar.png" alt="Rasin Gue"></figure><p class="title is-size-4 is-block line-height-inherit">Rasin Gue</p><p class="is-size-6 is-block">PhD in Progress</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Tsukuba, Japan</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">5</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/RasinGue" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/RasinGue"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/mizumori_setsu"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/rasin"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2021-04-12T10:35:55.000Z">2021-04-12</time></p><p class="title is-6"><a class="link-muted" href="/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/">GVGAI Book Chapter 3 - Planning in GVGAI</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-04-11T19:35:55.000Z">2021-04-11</time></p><p class="title is-6"><a class="link-muted" href="/2021/04/11/VGDL%E8%8C%83%E4%BE%8B%E8%A7%A3%E8%AF%BB/">VGDL范例解读</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-04-10T19:35:55.000Z">2021-04-10</time></p><p class="title is-6"><a class="link-muted" href="/2021/04/10/GVGAI%20Book%20Chapter%202%20-%20VGDL%20and%20the%20GVGAI%20Framework%20--%20Exercises/">GVGAI Book Chapter 2 - VGDL and the GVGAI Framework -- Exercises</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-03-23T19:35:55.000Z">2021-03-23</time></p><p class="title is-6"><a class="link-muted" href="/2021/03/23/%E9%87%8D%E8%BF%94Gamemaker%20Studio2/">重返Gamemaker Studio 入门篇2</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2021-02-23T19:35:55.000Z">2021-02-23</time></p><p class="title is-6"><a class="link-muted" href="/2021/02/23/%E9%87%8D%E8%BF%94Gamemaker%20Studio1/">重返Gamemaker Studio 入门篇1</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2021/04/"><span class="level-start"><span class="level-item">四月 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/03/"><span class="level-start"><span class="level-item">三月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2021/02/"><span class="level-start"><span class="level-item">二月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">六月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/GVGAI-AI/"><span class="tag">GVGAI; AI</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GVGAI-VGDL/"><span class="tag">GVGAI; VGDL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gamemaker-Studio/"><span class="tag">Gamemaker Studio</span><span class="tag is-grey-lightest">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VGDL/"><span class="tag">VGDL</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/joural/"><span class="tag">joural</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Rasin&#039;s Blog" height="28"></a><p class="size-small"><span>&copy; 2021 Rasin Gue</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://rasin.me',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>