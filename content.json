{"pages":[],"posts":[{"title":"GVGAI Book Chapter 2 - VGDL and the GVGAI Framework -- Exercises","text":"书籍网站本章原文本章练习 GVGAI环境配置Github中提供了GVGAI框架。这里使用与书中匹配的2.3版本来进行练习。 下载并安装 IntelliJIntelliJ下载地址与 JDK 下载地址。 下载安装完成后导入项目，如图所示： 运行项目首先我们先试着用GVGAI运行游戏。可以使用键盘直接控制游玩，或者使用示例agent来自动测试。 以玩家身份玩游戏在左边的 Project 导航中选择 src -&gt; tracks -&gt; singlePlayer -&gt; Test.java 双击打开。 为了顺利编译文件，根据一下图示顺序设定好配置。配置名可以任意选择。 确认之后点击右上角的绿色运行按钮或者使用快捷键 Shift+F10 即可开始运行。 默认启动的游戏是 Alians，玩家通过键盘方向键←→和空格键进行操作。 更改游戏在代码中的29行我们可以看到游戏集文件 examples/all_games_sp.csv。使用CSV插件可以看到游戏列表： 那么接下来在文件的 37行中，我们可以通过修改 gameIdx 来更改游戏。例如，将其修改为: 1int gameIdx = 9; 再次编译运行，游戏就变成了炸弹人： 用机器人玩游戏要使用示例Agent来运行集合中的游戏时，请注释掉第 49行（这行代码是给玩家试玩使用的），并解开第 52 行注释。 12345// 1. This starts a game, in a level, played by a human.//ArcadeMachine.playOneGame(game, level1, recordActionsFile, seed);// 2. This plays a game in a level by the controller.ArcadeMachine.runOneGame(game, level1, visuals, sampleRHEAController, recordActionsFile, seed, 0); runOneGame 第四个函数指定Agent的位置（默认是 Rolling Horizon Evolutionary Algorithm agent）。 文件中第 18 至 26行定义了本框架中包含的实例Agents，例如 Monte Carlo Tree Search agent 和 OLETS。 VGDLVGDL 游戏都存储在 example文件夹中。每个游戏类别都有一个文件夹：gridphysics 和 contphysics 包含具有传统和现实世界物理引擎的单人游戏，2player 中都是双人游戏，gameDesign 包含参数化的游戏。 修改游戏可以尝试在 example/gridphysics 中打开一个 VGDL文件，一般以 .txt 后缀结尾。学习VGDL不同的部分可以从修改内容的值开始。也可以根据你的想法在 InteractionSet 中添加新的规则或者新的贴图。有可能你也能创造新的游戏。 更改关卡可以通过修改例如 aliens_lvl0.txt 之类的文件来更改关卡，比如关卡的布局，贴图的初始位置等等。可以给关卡增加不同难度或者创造新的关卡。 提交到GVGAI比赛服务器一下是提交步骤： 在 GAGVI官网 创建账号。 登入并点击 Submit → Submit to Signle Player Planning。 您的控制器文件应命名为 Agent.java，并包含一个与您用户名相同的包，以 .zip 文件存储。网站中有更详尽的提交规范 填写需要的信息，并选择一个游戏集提交。您的代码将会在服务器上编译执行，具体提交信息可以在个人主页上查看。 一旦编译运行完成，你可以在排行版上看到您的结果。 如果您想参赛，可以先用示例代码提交测试。","link":"/2021/04/10/GVGAI%20Book%20Chapter%202%20-%20VGDL%20and%20the%20GVGAI%20Framework%20--%20Exercises/"},{"title":"独与孤","text":"2020年6月12日，已经是第26个生日了。我在今天收获了三个生日祝福，两个是不同阶段的同学，一个是网友。 首先应该感谢在这个世界上，在我没有声张的情况，还有人主动给我送来祝福。自然而然，“三个祝福”固然对于一些人来说过于少而感到可笑，我也一时因此气馁。相较于过去而言，在学生时代也有班级或者好友给予无论是口头还是礼物的祝福，或者是工作时公司的生日福利，一群人凑在一起吃吃喝喝来庆祝某几个相同月份的人生日，确实仅有的几个口头祝福是寒酸了一点吧。 比起回忆，更重要的是心意。除了家人以外，有牵挂你的朋友、同学以及同事，或者相隔千里之外的网友，近年来已逐渐不敢奢求了。主要的原因当然是自己不去表达自己的期望，还有逐渐减少的社交频次，以及就是在交往过程中更加谨慎了吧。为了不触及对方的神经令其敏感，主动减少需要表达的内容，以获取交往过程中微妙的距离感，得到四平八稳的人际关系。这样的行为导致的结果也应该是咎由自取吧。 而心态的转变在于，从“仅有”三个，到“还有”三个，是不是已经开始接受了这样的现实呢。已经还有三个了，就不用提过多要求了吧。当然，同时还要感谢银行、保险和社交平台等等，从冷冰冰的机器定期服务中用热情洋溢的字眼提醒我今天生日这回事。感谢！ 说起来，自今年年初离职开始，已经在家三个月有余了。不知不觉一年已经过去二分之一，一边惊讶于白驹过隙，一边哀伤于毫无长进。三口之家的双职工家庭，离职的只可能独自一人在家，除了父母下班之后的一些交流，其余时间基本都是一个人度过。从一开始的放松，自由的心态，到现在习惯于一人食、一人眠，甚至有时开始渴望与人对话交流。人果然是社会性动物，一个人独处久了，果然还是会想念回归社会吧。但我依然以疫情为由避免了很多聚餐，以繁忙为由婉拒了一些聚会，以抱恙为由谢绝了不少机会。 原本定好的计划已经支离破碎，距离开始新生活的日子遥遥无期。 一个人的时候总是喜欢胡思乱想，便开始悲天悯人、顾影自怜起来了。 独处给了我更多的时间，而我却任其挥霍。 然而为什么不换个方向来考虑呢？ 一个房间便是一个世界。由于我在其中，因此手头的工具便赋予了意义，创造便有了容身之处，思想虽难以碰撞，却可以孜孜不倦取前人及当代精华。 可以调素琴，阅金经。无丝竹之乱耳，无案牍之劳形。 乐观地来说，独处也算是独而不孤吧。 避免了纷繁的外界，无需根据流行刻意，不要依照指示而执行。独处之时，自己便是全部，思绪漫布也无伤大雅，天马行空也安之若素。不用活在眼光之中，不须听取口舌之燥。这样也算是一种解脱。 虽然前途未卜，但是这样的日子还能持续多久呢？当一切走上正轨，也就是宣告一个时期的结束了。 这一段悠长假期，没有艳遇和激情，来弥补的是思考和自省。 漫天烦恼和忧愁的云雾，何时可以拨云见日呢？ 独处给了我更多的时间，我愿窥见星辰。","link":"/2020/06/12/%E7%8B%AC%E4%B8%8E%E5%AD%A4/"},{"title":"重返Gamemaker Studio 入门篇2","text":"在线文档: GameMaker Studio 2 Manual官方社区: GameMaker Community知识库：GameMaker Knowledge Base 本系列参考的教程：GameMaker Studio 2: Complete Platformer Tutorial 添加枪械人物将会携带枪支进行射击。首先要添加枪械的贴图和对象。由于枪械是一个长矩形，并且根据常识，人物应该在枪械的后半部把持着。因此，将枪械的原点设在偏后半部的中心位置比较妥当。 再者，枪械一般位于胸部位置，而玩家贴图是Q版一比一身材，因此将其置于身体中心再向下一些的位置。我们在 oGun 对象的 BeginStep 事件中添加代码： 12x = oPlayer.xy = oPlayer.y + 9 //较为合适的位置 我们希望枪械的前端将会指向鼠标的方向，并且鼠标在人物左右的时候，枪械也会自动跟随鼠标翻转： 1234567image_angle = point_direction(x, y, mouse_x, mouse_y) //鼠标的坐标if (image_angle &gt; 90) and (image_angle &lt; 270){ //逆时针计算角度，零度为正下方 image_yscale = -1}else{ image_yscale = 1} 添加子弹子弹是一个两帧动画，首先是一个圆形，之后变成一个带着小尾巴的圆。我们希望子弹在发射出去之后，保持第二帧动画不变，直到碰到墙壁消失。那么可以通过 oBullet对象的 Animation End 事件代码实现： 12image_speed = 0 //当动画结束时，将动画速度设为0，即不再播放image_index = 1 //将动画帧数设为第二帧 接下来，在 Post Draw 事件中，我们添加碰到墙体后子弹销毁的代码： 12if (place_meeting(x, y, oWall)) instance_destroy() //该实例销毁 这里的 Post Draw 事件，是指在绘制一旦结束之后就立即检测。官方文档的解释是： The Post Draw event is triggered after the standard draw events, but before the Draw GUI events. Like the Pre Draw event, it is based on the size of the screen buffer size, and is placed before the Draw GUI events to enable you to perform post-processing effects and other things on a full screen basis simply and easily without interfering with any HUD/GUI elements that you may have in your game. 论坛中网友的解释是 the Post Draw event is the moment in between the Draw events and the image being sent to the screen. 简单点理解就是，游戏引擎在绘制之后，还没有把绘制完成的东西送到显示屏上就立即执行的事件。 枪械射击与后坐力枪械连击中间需要加入一个延迟，并且枪械在发射子弹的过程中最好还带有一个后坐力的效果。首先我们先在 oGun 的 Create 事件中声明一下相关变量: 12firingdelay = 1 // 发射间隔recoil = 0 // 后坐力 依旧是在 Begin Step 事件中，我们添加对于射击延迟和后坐力的一个检测： 12345678910111213141516firingdelay = firingdelay - 1 // 每个时间片减少1计时recoil = max(0, recoil - 1) // 后坐力取0和当前值减1的最大值if (mouse_check_button(mb_left)) &amp;&amp; (fd&lt;0){ //当鼠标左键点击并且延迟计时小于0时 recoil = 4 //设定后坐力 fd = 5 //设定设计间隔 with (instance_create_layer(x, y, &quot;Bullets&quot;, oBullet)){ //with 语句 speed = 25 // 将对应创建的新bullet对象赋予速度 direction = other.image_angle + random_range(-3, 3) // other 指with中指代的对象，这里加入一个随机数使得子弹不会单纯往一个方向设计，而是在一个小的随机范围内发射 image_angle = direction //重新设定子弹行进的方向 } }x = x - lengthdir_x(recoil, image_angle) //往发射角度的反向延长线上后退y = y - lengthdir_y(recoil, image_angle) 官方文档中对于 with 语句的解释是： In a number of cases you want to do a lot more than just change a single variable within those other instances, and may want to perform more complex code actions that require multiple functions and lines of code. Once the expression has set the scope of the with, the statement will then be executed for each of the indicated instances, as if that instance is the current (self) instance. 也就是说，with 可以再指定一个新对象，这个新对象在 with 语句中用 other 来指代。 这时候要记得在 Room1 中添加两个新层 Bullets 和 Gun，这两层应置于 Player上方。","link":"/2021/03/23/%E9%87%8D%E8%BF%94Gamemaker%20Studio2/"},{"title":"VGDL范例解读","text":"A Video Game Description Language for Model-based or Interactive Learning Alians VGDLVGDL论文简介pyVGDL 是一种视频游戏描述语言，以促进大型或多样化游戏组合的生成，这些游戏组合也可以用于评估具有通用性的体系结构和算法，例如强化学习和进化搜索。为了使这一目的更加可行，作者将游戏生成领域限制为2D街机风格游戏，其具有足够多样化的空间。 pyVGDL应该具有清晰，易读且明确的特性。其词汇应具有较高的表达力，比你更具有相当新颖的扩展性。其表示结构应该易于解析，可以自动生成游戏，默认设置和健全检查能够使大多数随机游戏描述真正可玩。 pyVGDL 语言基于Python语言和 pygame库开发。完整开源代码地址。 整个游戏将限制在一个二维矩形空间内，所有游戏相关的对象都再此空间内。受全局或特定于对象的规则和玩家动作的影响，对象可以移动，与其他对象交互，消失或生成新对象。 一个游戏分为两个部分：关卡描述描述了所有对象的位置和游戏2D布局； 游戏描述描述了游戏中所有动态和潜在的对象互动。 一个关卡描述的示例：具有固定的长，，用不同的符号代表不同的对象。例如：A代表在左上角生成的玩家，需要找到钥匙 +到目的地 G离开迷宫。通过避开或击杀怪物 1来完成关卡。其余的 w代表迷宫的墙体。 而游戏描述则由四大块指令组成。以下使塞尔达传说的一个示例： LevelMapping 定义了如何将对应字符从关卡描述映射到对象。例如 1 可以映射到 monster 类。 SpriteSet 定义了对象类，都是由一个抽象类 VGDLSprite 派生出来的。对象类以树的形式 （使用缩进）来组织，子类将会继承其父类的属性。例如玩家的 avatar 类中就有两个子类，其中一个是得到钥匙的，另一个没有。所有的类都可以使用关键字参数，例如 key 和 goal 就是用了不同的 color参数，都具有相同的 Immovable 参数。 InteractionSet 定义了当两个对象碰撞时将会发生的潜在事件。这些互动由事件方法定义，也可以使用参数。例如，sword 可以击杀 monster， monster 可以击杀玩家，没有对象可以穿透 walls，当林克找到 key 对象时，avatar 类将会转换。 TerminationSet 定义了游戏结束的不同方法，每一行都是一个结束评判。例如，是否到达 goal。 还有一些其他的设置例如： 物理类型 ：continuous, grid based, friction, gravity, … 移动动态：straight, random motion, player-control, … 互动作用：bouncing, destruction, spawning, transforming, … 特性 生成，克隆和消除对象，从一种类型转换到另一种 自走式对象运动，采取一致或随机的动作，或者不规律变化 非确定性的追赶和逃避行为 根据用户操作或碰撞效果触发的固定或随机时间表在任意对象位置生成的发射对象 粘性，即一个物体拉动另一个物体 其他对象或屏幕边缘的跳动和环绕行为 将物体传送到固定或随机的终端位置 连续的物理效应，例如惯性，摩擦和重力 随机影响，例如沿当前方向滑动或阵风 语法pyVGDL 是基于 Python语言本身。游戏描述必须严格保持一个树形结构，更类似于XML 样式。 整个解析器包含了游戏描述和关卡描述的解析。解析和初始化在一秒之内完成，基本可以使游戏马上可玩。 解释器和接口 玩家类型：支持玩家直接用键盘参与，以及机器人调用接口。接口符合 PyBrain机器学习库的 Agent/Environement/Task模型，通过 getSensors和performAction方法来进行互动。 玩家数量：支持单人（目前已支持多人） 视角：默认游戏以鸟瞰视角游玩，而且全地图可见。我们也提供了第一人称视角，这样游戏将只有部分可见。 观察：它们可以以中等分辨率的图像或“干净”的形式在视觉上呈现，仅表示功能不同的组件。然而，强大的agent能够像人类一样识别视觉流。 模型：我们提供了一种转换工具，可以将游戏动态转换为马尔可夫决策过程的完整转换矩阵 。这仅对状态组合不会爆炸增加的游戏是可行的。 VGDL 范例Lunar LanderLunar Lander的游戏描述文件为： 12345678910111213BasicGame LevelMapping G &gt; pad SpriteSet pad &gt; Passive color=BLUE avatar &gt; InertialAvatar physicstype=GravityPhysics InteractionSet avatar wall &gt; killSprite avatar EOS &gt; killSprite pad avatar &gt; killIfSlow TerminationSet SpriteCounter stype=pad limit=4 win=True SpriteCounter stype=avatar win=False 其中之一的关卡描述文件为： 123456789101112wwwwwwwwwwwwwwwwwwwwwwwwwwww w w w A wwww www wwww w w wwwwwwwwGGw wwwwwGGGwwwwwwwwwwwww wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww 从关卡描述中我们可以看出，A为玩家，G为降落地点，w 为墙体。 LevelMapping: G为降落地点 SpriteSet: pad 被设为蓝色，玩家avatar的物理类型是受到重力影响的。 InteractionSet： avatar 碰到墙体即被摧毁 avatar 飞出游戏窗体外也被摧毁 avatar 碰到 pad 如果速度过快也被摧毁 TerminationSet: 由于总共落地点有五个，到达目的地会自动消除一个，因此剩下四格降落点时玩家胜利，否则失败。 Aliens游戏描述文件为： 1234567891011121314151617181920212223242526272829303132333435363738BasicGame square_size=32 SpriteSet background &gt; Immovable img=oryx/space1 hidden=True base &gt; Immovable color=WHITE img=oryx/planet avatar &gt; FlakAvatar stype=sam img=oryx/spaceship1 missile &gt; Missile sam &gt; orientation=UP color=BLUE singleton=True img=oryx/bullet1 bomb &gt; orientation=DOWN color=RED speed=0.5 img=oryx/bullet2 alien &gt; Bomber stype=bomb prob=0.01 cooldown=3 speed=0.8 alienGreen &gt; img=oryx/alien3 alienBlue &gt; img=oryx/alien1 portal &gt; invisible=True hidden=True portalSlow &gt; SpawnPoint stype=alienBlue cooldown=16 total=20 img=portal portalFast &gt; SpawnPoint stype=alienGreen cooldown=12 total=20 img=portal LevelMapping . &gt; background 0 &gt; background base 1 &gt; background portalSlow 2 &gt; background portalFast A &gt; background avatar TerminationSet SpriteCounter stype=avatar limit=0 win=False MultiSpriteCounter stype1=portal stype2=alien limit=0 win=True InteractionSet avatar EOS &gt; stepBack alien EOS &gt; turnAround missile EOS &gt; killSprite base bomb &gt; killBoth base sam &gt; killBoth scoreChange=1 base alien &gt; killSprite avatar alien &gt; killSprite scoreChange=-1 avatar bomb &gt; killSprite scoreChange=-1 alien sam &gt; killSprite scoreChange=2 其一关卡描述文件为： 12345678910111.............................000...........................000.......................................................................................................................................................000......000000.....000......00000....00000000...00000.....0...0....00....00...00000..................A............. 从描述文件我们可以看出： LevelMapping: . 为背景 0为墙体（基地） 1 为敌人产出生点 2产生速度较快 A 为玩家 SpriteSet: 背景不可移动，贴图位置为 oryx/space1，表现为隐藏不可互动 基地不可以调动，颜色为白色，贴图位置 oryx/planet 玩家属于 FlakAvatar类，子弹类型为 sam，贴图位置 oryx/spaceship1 导弹属于 Missile 类，分为两种： sam 是向上射击的，颜色为蓝色，全屏只能存在一个，贴图位置 oryx/bullet1 bomb 是向下掉落的，颜色为红色，速度限制为 0.5，贴图位置 oryx/bullet2 敌人也有两种，属于Bomber类，子弹卫星为 bomb， 射击概率为 0.01，冷却时间为 3，速度为 0.8 绿色敌人贴图 oryx/alien3 蓝色敌人贴图 oryx/alien1 传送点不可见，也不可互动 慢速传送点产生蓝色敌人，冷却时间为 16，总计产生20个 快速传送点产生绿色敌人，冷却时间为 12，总计产生20个 InteractionSet 玩家飞出屏幕将会退格，即卡住不会前进 机器人飞出屏幕则会反向继续前进 子弹飞出屏幕则直接销毁 如果基地碰到bomb则两个都被销毁 如果基地碰到sam则两个都被销毁，加一分 如果基地碰到敌人，基地被销毁 如果玩家碰到敌人，玩家被摧毁，扣一分 如果玩家碰到bomb，玩家被摧毁，扣一分 如果敌人碰到sam，敌人被摧毁，得两分 TerminationSet 如果玩家数量为0，即玩家被摧毁，游戏失败 如果传送门和敌人的数量都为0，则游戏胜利","link":"/2021/04/11/VGDL%E8%8C%83%E4%BE%8B%E8%A7%A3%E8%AF%BB/"},{"title":"重返Gamemaker Studio 入门篇1","text":"空有雄心壮志，不如脚踏实地从简单做起。 经历了三年空窗期，虽说实际情况产生了不可计量的变化，也和当时想做游戏的简单初衷相去甚远。但愿望如果不开始付诸实际，只会停留在空想。因此还是准备从简单做起，不想因为复杂的实现和编程花费太多时间，而把重心侧重在玩法和构思上面，GameMaker Studio 2 貌似是一个比较折中的选择。闲话少叙，从一个简单的平台冒险类游戏下手，基本能够达到目前构思游戏demo的制作需求。本系列的目的是在跟着教程实践的基础上，对游戏制作过程的一个简单记录，仅供自己回顾，不做教程目的。 在线文档: GameMaker Studio 2 Manual官方社区: GameMaker Community知识库：GameMaker Knowledge Base 本系列参考的教程：GameMaker Studio 2: Complete Platformer Tutorial 界面介绍在打开游戏IDE之后，我们可以看到几个区域。如图所示，中间部分是工作区，所有基本的元素编辑和代码撰写都在这里。右边是素材区，已经被多个文件夹详细划分。左上是菜单栏和工具栏，最左一栏为房间设置栏，之后再详细讨论其使用方法。 工作区的操作同大多数游戏一样，通过滚轮滑动调整上下，点击中键进行移动，按住Ctrl键加上滚轮滑动可以控制工作区的界面缩放，也可以使用 Ctrl + + 和 Ctrl + - 达到相同效果。 再进行工作的时候，可以使用快捷键 F12 将工作区最大化，方便编辑。 创建贴图可以直接在工作区里点击 右键→Assets→Create Sprite；或者在素材区对应的文件夹里如前者一般创建。唯一的区别是，直接在工作区里创建的文件存储在根目录，而对应文件夹创建可以更加分门别类，当然也可以重新拖放文件达到相同效果。同理，其他需要创建的东西也可以这样操作。 以下就是一个空的贴图文件配置。 贴图可以根据我们的需要进行命名，命名一般需要规则，如玩家静止贴图用 sPlayer, 玩家跑动贴图用 sPlayerR，玩家跳跃贴图用 sPlayerA。下方的 Size 需要注意，一般是 64*64 的像素大小，也可以点击按钮进行调整。右边的 Edit Image 可以直接在编辑器里面编辑。我个人觉得还是使用更完备的外部编辑器画好再导入进来，比如 Aseprite 或 Photoshop等等。下面的 Import 按钮可以导入图片。导入图片可以是单张贴图或者多帧动画。注意这里导入的动画实际上是拼贴好的 png 文件，文件名以 _strip(num) 结尾，其中 num 是实际上帧的数量。这样导入的图片将会自动被切割成 num 数量的帧。如下图所示，一张拼贴好的4帧 sPlayer_r_strip4.png 文件： 左下角的 Collision Mask 是用于检测游戏对象碰撞的大小，可以通过手动自行设置或者自动检测来调整。 右侧是动画界面，右上角是动画帧率。注意这里的帧率仅用于显示，而不是指游戏内的实际帧率。右边的坐标指定该贴图的圆心位置，一般可以直接使用 Middle Centre 让系统自动指定。 这里我们创建了两个基本的贴图：sPlayer和 sWall，并将素材导入。 创建对象贴图只是纯粹的图片，不能执行游戏中的指令和效果，因此就需要创建对象并绑定贴图。首先，我们先创建一个玩家对象 oPlayer，并将刚才创建好的 sPlayer 进行绑定。 下方的 Events 可以用来管理对象相关的所有事件。点击并创建新的事件。首先，Create 事件对应在对象创建时，我们需要初始化一些简单的变量： 1234hsp = 0 //水平速度vsp = 0 //垂直速度grv = 0.3 //重力walksp = 4 //行走速度 紧接着，我们创建 Step事件。Step 事件管理每个时间片里面需要执行的内容，因此代码会较为复杂。首先定义以下按键： 1234//Get Player Inputkey_left = keyboard_check(vk_left) || keyboard_check(ord(&quot;A&quot;)) //方向键左或者键Akey_right = keyboard_check(vk_right)|| keyboard_check(ord(&quot;D&quot;)); //方向键右或者键Dkey_jump = keyboard_check_pressed(vk_space)|| keyboard_check_pressed(ord(&quot;W&quot;)); //空格键或键W，仅需点击即可 这样就定义好了基本的行动按键。接下来，对应的按键要加上其逻辑才能有实际意义。我们继续定义一下运动的状态： 123var move = key_right - key_left // `var` 用于声明局部变量hsp = move * walksp // 水平速度等于行动方向乘行走速度vsp = vsp + grv; // 垂直速度等于现有垂直速度加上重力速度 首先定义了一个临时变量 move。move 在这里是一个布尔值，当 key_right为 True 且 key_left 为 False 时，move值为 1 ；当 key_right为 False 且 key_left 为 True 时，move 值为 -1 。这样就可以将作为一个方向的标识。 正如我们在 Create 事件中定义的几个基础的速度变量，在 Step 事件中需要对行进速度进行实时更改。对于水平速度如此定义无可厚非，但垂直速度并没有按照物理学的实际情况算上加速度，只是简单的通过在每个时间片减去重力的速度达到下落的效果。 碰撞检测如果不做碰撞检测，那么人物在水平行进和下落的时候就不会被墙阻挡住，就没有办法进行游戏。因此要对人物和墙体之间做碰撞检测。先从跳跃开始： 1234// Jumpif (place_meeting(x, y+1, oWall)) &amp;&amp; (key_jump){ vsp = -7} place_meeting 函数用于检查某个对象实例的 Collision Mask 与另一个实例或对象的所有实例的碰撞检测。因此这个函数可以检测玩家对象和所有的墙体，而不需要对单个墙体进行设定。由于房间坐标的左上顶点是 (0, 0)，因此垂直的负方向是向上，因此向上跳跃的速度设为负值。触发跳跃的条件是当玩家位于墙对象上分且按下跳跃。 水平移动要算上玩家的移动速度。因此在 place_meeting 函数中需要注意： 12345678if (place_meeting(x+hsp, y, oWall)){ //加上玩家的速度 也就是下一个时间片原本的位移 while (!place_meeting(x+sign(hsp), y, oWall)){ //当还没碰到墙时要继续移动，这里用方向表示更简洁 x = x + sign(hsp) //继续移动到墙边 } hsp = 0 //将移动速度设为0}x = x + hsp; //更改玩家横坐标位置 同理，垂直移动也可以用类似的代码来实现： 123456789//Vertical Collisionif (place_meeting(x, y+vsp, oWall)){ while (!place_meeting(x, y+sign(vsp), oWall)){ y = y + sign(vsp); } vsp = 0;}y = y + vsp; 动画效果在移动的基础上增加动画能使得游戏演示看起来更自然生动。这里重新创建两个贴图：sPlayerR 为奔跑动画，sPlayerA 为在空中的动画。我们需要玩家在跑动的时候播放奔跑动画，在跳跃的时候播放空中的动画。现在依旧需要用碰撞来检测玩家的具体位置： 12345678910111213141516171819if (!place_meeting(x, y+1, oWall)){ //不和墙体接触，即在空中时 sprite_index = sPlayerA //将动画切换成空中动画 image_speed = 0 // 将动画循环速度常数设为0，即整个动作只播放一次 if (sign(vsp) &gt; 0){ //若玩家处于下落状态时 image_index = 1; //仅播放第二帧 } else{ image_index = 0; //播放第一帧 }}else{ //在地面的情况 image_speed = 1; //常速播放动画 if (hsp == 0){ sprite_index = sPlayer //播放静止动画 } else{ sprite_index = sPlayerR //播放运动动画 }} 跑动也有正反方向。Gamemaker Studio 提供了一个取巧的功能使得美术不需要画两个方向的动画： 123if (hsp !=0){ //在水平运动的时候 image_xscale = sign(hsp) //运动方向的正负决定动画方向} 房间设置做好了基本的对象和相关事件，我们应该将其放到实际的游戏中进行测试。在 Rooms 文件夹中创建一个新房间 Room1。界面的左上方有一个房间图层，如同 Photoshop 一样，居于最上的最前，居于最下的最后。除了原有的 Background，我们创建两个新的图层 Player和 Wall。 之后我们将玩家对象和墙体对象拖入，按住 alt 键可以批量生成。如下图就是一个房间的示例： 如果没有什么问题的话，点击上方的 Run 按钮或快捷键 F5就可以运行游戏了。","link":"/2021/02/23/%E9%87%8D%E8%BF%94Gamemaker%20Studio1/"},{"title":"GVGAI Book Chapter 3 - Planning in GVGAI","text":"书籍网站本章原文本章练习 简介Planning是指制定行动计划以解决给定的问题。当给定当前状态和玩家要采取的行动时，可以使用环境模型来模拟可能的未来状态，该模型将被称为前向模型（Forward Model）。Monte Carlo Tree Search（MCTS）和Rolling Horizon Evolutionary Algorithms（RHEA）是构建大多数Planning Ai的基础，这两种方法互不相同：第一种方法从可能的游戏动作和状态种构建树，提取统计信息以决定在任何给定状态下下一步该怎么做；第二种方法一开始就定好整个计划，并使用进化计算来组合和修改它们，从而最终获得在游戏中执行的最佳选择。 GVGAI问题可以看作是多目标优化问题：游戏中的计分系统可能具有欺骗性，并且AI不仅需要专注于获得得分（如在传统的街机游戏中一样），而且还需要着眼于解决问题和赢得比赛，甚至还要考虑时间限制。 蒙特卡洛搜索树该算法通过一次添加单个节点来构建以不对称方式增长的搜索树，并通过使用从节点状态到游戏结束的自玩游戏来估算其游戏理论值。 书中的每个节点都会保存某些统计数据，这些统计数据表明在状态 \\(s\\) 下选择动作 \\(a\\) 时获得的奖励实验均值 \\(Q(s, a)\\)，从给定状态 \\(s(N(s, a))\\) 以及访问状态 \\(s\\) 的次数 \\(N(s)\\)。该算法通过模拟游戏中的动作，在连续的迭代中构建树，并根据这些统计信息做出选择。 MCTS的每个迭代都基于这几个步骤： 树选择 扩展 模拟 后向传播 刚开始，树只由根节点组成，存储了当前的游戏状态。在扩展 步骤中，如果游戏还未结束，树从根部开始搜索到一个最大深度。在这一步中，动作可以用 multi-armed bandit策略将其应用到前向模型中。 Multi-armed bandit 策略来源于一个多臂老虎机。当摇动杆时，从一个未知的概率分布返回一个奖励 \\(r\\)。这个问题的目的是在按一定顺序摇动杆后最大程度减少后悔（或者最大化累计奖励）。这里后悔被定义成一个当选择到一个并非最优的杆时的机会损失。好的政策通过平衡对可用杆的探索与对过去提供更好回报的杆的利用之间的平衡来选择行动。 Upper Confidence Bound (UCB1)： $$a* = \\underset{a\\ \\in \\ A( s)}{\\mathrm{argmax}} \\ \\Bigl{Q( s,\\ a) \\ +\\ C\\sqrt{\\frac{\\ln N( s)}{N( s,a)}}\\Bigr}$$ 该函数的目标是找到一个动作 \\(a\\)可以使UCB1函数最大化。\\(Q(s, a)\\)看作是 发掘*项，第二项是 *探索 项。探索项与给定状态 \\(s\\)，每个动作 \\(a\\)被选择的参数\\(N(s,a)\\)，以及从当前状态中选取动作的数量\\(N(s)\\)。参数 \\(C\\)用于平衡发掘与探索。当\\(C\\) 为0时，UCB1采用贪婪策略每次都选择平均当前收益最高的动作。如果奖励 \\(Q(s, a)\\)被正则化到 \\([0, 1]\\) 之间，常用的常数值为 \\(\\sqrt{2}\\)。不同游戏常数值的选择可能不同。 在 树选择 步骤中，直到找到子节点少于动作数量的节点。 此时，在 扩展 步骤加入一个子节点，开启 模拟 步骤。从新节点开始，MCTS执行蒙特卡洛模拟。这时候选择一个随机的动作（均匀随机或有偏随机）一直到游戏结束（或到达一个预定义的深度）。最后，在 反向传播 步骤中，使用状态评估中获得的奖励，为遍历的每个节点更新统计量 \\(N(s), N(s, a), Q(s, a)\\)。这些步骤会循环执行，直到达到一个结束条件（例如迭代次数或者预计的时间）。 直到所有的迭代完成，MCTS将会推荐agent在游戏中采取的动作。该推荐策略根据存储在根节点中的统计信息来确定动作。可能推荐最近常采用的动作或者得到最高平均收益的策略，也可能直接计算公式得到返回的动作。以下为MCTS算法的伪代码： MCTS被认为是随时可用的算法，因为它能够在任何时刻提供有效的下一步选择。 这不同于其他算法（例如单人游戏中的A*算法，以及两人游戏中的标准“Min-Max”），这些算法通常仅在完成后才提供给下一次游玩。这使MCTS在实时领域十分合适，在实时域中，决策时间预算受到限制，从而影响了可以执行的迭代次数。 GVGAI也提供了基础版本的MCTS。在实际应用中，\\(C\\) 选取为 \\(\\sqrt(2)\\)，且rollout深度定为10 。在模拟阶段结束时达到的每个状态都使用该时刻的游戏得分进行评估，并在比赛期间见过的最小和最大得分之间进行归一化。 如果状态为终局，则分配的奖励为较大的正数（如果游戏获胜）或负数（如果游戏输了）。 虽然MCTS在GVGAI平台上的表现很好，但是没有游戏相关的知识支撑算法。Value function 仅基于得分和游戏结束状态，这些概念存在于所有游戏中，因此通常在GVGP方法中使用。 代码示例以一个简单的游戏为例，该游戏的目的是使每次动作选取数字的累积和接近0.动作的可选范围是 [-2, 2, -3, 3] * 回合数。 首先构建 State 类： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class State(): NUM_TURNS = 10 #最多10回合 GOAL = 0 #目标是累计和为 0 MOVES = [2, -2, 3, -3] # 动作可选范围 MAX_VALUE = (5.0 * (NUM_TURNS - 1) * NUM_TURNS) / 2 # 最大值为225 num_moves = len(MOVES) # 动作数量 # 初始化类 # 累计和为0，动作为空列表，总回合数由传入参数决定 def __init__(self, value=0, moves=[], turn=NUM_TURNS): self.value = value self.moves = moves self.turn = turn # 下一个状态 # 通过当前状态得到下一状态 def next_state(self): # 从回合数乘动作的列表中随机选择 nextmove = random.choice([x * self.turn for x in self.MOVES]) # 更新下一个状态的成员值 next = State(self.value + nextmove, self.moves + [nextmove], self.turn - 1) # 返回下一个状态 return next # 终结状态 def terminal(self): # 如果剩余回合数为0 if self.turn == 0: # 结束 return True return False # 奖励 def reward(self): # 游戏的奖励定义为 # 用1减去当前值减去目标值的绝对值除以最大值 # 实际上就是归一化之后距离0越近奖励越多 r = 1.0 - (abs(self.value - self.GOAL) / self.MAX_VALUE) return r # 若对象在其生命周期内保持不变，而且能与其他对象相比较，那么这个对象是可哈希的 # 通过__hash__返回一个int值，用来标记这个对象。 # 这里是通过操作序列来标记两个状态是否相同 def __hash__(self): return int(hashlib.md5(str(self.moves).encode('utf-8')).hexdigest(), 16) # 在调用 `==` 操作符，，实际上是调用 `__eq__`方法 def __eq__(self, other): if hash(self) == hash(other): return True else False # __repr__主要用于调试和开发 # 用于打印内容 # repr()更能显示出对象的类型、值等信息，对象描述清晰 def __repr__(self): s = &quot;Value: %d; Moves: %s&quot; % (self.value, self.moves) return s 之后定义蒙特卡洛树类： 12345678910111213141516171819202122232425262728293031class Node(): def __init__(self, state, parent=None): self.visits = 1 # 被访问次数默认为1 self.reward = 0.0 # 奖励为0 self.state = state # 初始状态 self.children = [] # 子节点为空列表 self.parent = parent # 初始父节点 # 为蒙特卡洛树增加子节点 def add_child(self, child_state): # 直接在子节点列表里面添加一个实例，状态为子节点状态，子节点的父节点是自己 child=Node(child_state, self) self.children.append(child) # 更新状态 def update(self, reward): # 更新奖励，且访问数量加1 self.reward += reward self.visits += 1 # 判断是否完全拓展 def fully_expanded(self): # 如果子节点的数量已经与状态中的动作数量相等了，则已搜索完毕 if len(self.children) == self.state.num_moves: return True return False # 打印内容 def __repr__(self): s = &quot;Node; children: %d; visits: %d; reward: %f&quot; % (len(self.children), self.visits, self.reward) return s 在定义完基本数据结构之后，就要定义策略方法了。首先定义默认策略： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081def DEFAULTPOLICY(state): # 如果还未搜索结束 while state.terminal() == False: # 则继续搜索 找到下一个状态 state = state.next_state() # 返回奖励值 return state.reward()def EXPAND(node): # 首先先找出已经搜索过的子节点，保存下来 tried_children = [c.state for c in node.children] # 找到该状态的下一个状态 new_state = node.state.next_state() # 循环验证，若该状态已被尝试 while new_state in tried_children: # 再增加一个新状态，直到没有重复 new_state = node.state.next_state() # 将新状态加入子节点 node.add_child(new_state) # 返回最后一个节点 return node.children[-1]def TREEPOLICY(node): # 如果有多种选择时且你不想要完全扩展时的一个强制“发掘“的奇技淫巧 # 在还未完结 时 while node.state.terminal() == False: # 如果子节点数量为0 if len(node.children) == 0: # 扩展 return EXPAND(node) # 随机，二分之一概率 elif random.uniform(0, 1) &lt; 0.5: # 找到最佳子节点 node = BESTCHILD(node, SCALAR) # 否则 else: # 如果还未完全扩展 if node.fully_expanded() == False: # 扩展 return EXPAND(node) # 否则返回最佳子节点 else: node = BESTCHILD(node, SCALAR) return nodedef BESTCHILD(node, scalar): # 最高分初始为0 bestscore = 0.0 # 最佳子节点列表为空 bestchildren = [] # 遍历所有的子节点 for c in node.children: # 根据公式计算 # 发掘项 exploit = c.reward / c.visits # 探索项 explore = math.sqrt(2.0 * math.log(node.visits) / float(c.visits)) # UCB1总分为两者之和 score = exploit + scalar * explore # 找到最高分 if score == bestscore: bestchildren.append(c) if score &gt; bestscore: bestchildren = [c] bestscore = score # 如果最佳子节点数量为0，则报错 if len(bestchildren) == 0: logger.warn(&quot;OOPs: no best child found, probably fatal&quot;) # 随即返回一个最佳子节点 return random.choice(bestchildren)# 反向传播def BACKUP(node,reward): while node!=None: node.visits+=1 node.reward+=reward node=node.parent return 总搜索函数为： 1234567891011121314151617# 输入耗费预算和根节点def UCTSEARCH(budget, root): # 在预算范围内循环 for iter in range(int(budget)): # 每10000次打印一次 if iter%10000 == 9999: logger.info(&quot;simulation: %d&quot; %iter) logger.info(root) # 通过TreePolicy找到最佳子节点 front = TREEPOLICY(root) # 得到奖励 reward = DEFAULTPOLICY(front.state) # 反向传播 BACKUP(front, reward) # 返回最佳策略 return BESTCHILD(root, 0) 那么一个完整的执行过程写在 main 函数中： 12345678910111213141516171819if __name__ == '__main__': parser = argparse.ArgumentParser(description='MCTS research code') # 模拟预算参数 parser.add_argument('--num_sims', action=&quot;store&quot;, required=True, type=int) # `levels` 是使用MCTS挑选最佳子节点的次数 parser.add_argument('--levels', action=&quot;store&quot;, required=True, type=int, choices=range(State.NUM_TURNS)) args = parser.parse_args() # 定义空树 current_node = Node(State()) for l in range(args.levels): current_node = UCTSEARCH(args.num_sims / (l + 1), current_node) print(&quot;level %d&quot; % l) print(&quot;Num Children: %d&quot; % len(current_node.children)) for i, c in enumerate(current_node.children): print(i, c) print(&quot;Best Child: %s&quot; % current_node.state) print(&quot;--------------------------------&quot;) 若 num_sims 为 100000，深度 levels 为 9，一次模拟结果为： 12345678910111213141516171819202122232425262728293031323334353637383940414243level 0Num Children: 20 Node; children: 0; visits: 2; reward: 0.9288891 Node; children: 0; visits: 2; reward: 0.920000Best Child: Value: -30; Moves: [-30]--------------------------------level 1Num Children: 10 Node; children: 0; visits: 2; reward: 0.911111Best Child: Value: -3; Moves: [-30, 27]--------------------------------level 2Num Children: 10 Node; children: 0; visits: 2; reward: 0.813333Best Child: Value: -27; Moves: [-30, 27, -24]--------------------------------level 3Num Children: 10 Node; children: 0; visits: 2; reward: 0.826667Best Child: Value: -48; Moves: [-30, 27, -24, -21]--------------------------------level 4Num Children: 20 Node; children: 0; visits: 2; reward: 0.8488891 Node; children: 0; visits: 2; reward: 0.764444Best Child: Value: -30; Moves: [-30, 27, -24, -21, 18]--------------------------------level 5Num Children: 0Best Child: Value: -20; Moves: [-30, 27, -24, -21, 18, 10]--------------------------------level 6Num Children: 0Best Child: Value: -12; Moves: [-30, 27, -24, -21, 18, 10, 8]--------------------------------level 7Num Children: 0Best Child: Value: -6; Moves: [-30, 27, -24, -21, 18, 10, 8, 6]--------------------------------level 8Num Children: 0Best Child: Value: -12; Moves: [-30, 27, -24, -21, 18, 10, 8, 6, -6]-------------------------------- 基于知识的快速进化MCTSMCTS中的快速进化KB Fast-Evo MCTS 使用进化算法从环境中来学习rollout polic。该算法使用进化方法来调整一系列权重 \\(w\\)对蒙特卡洛模拟进行偏移。这些权重可用于结合针对当前游戏状态提取的一组固定功能来选择每个步骤的动作。 每一次 rollout 均使用最后到达的状态值作为适应性对单组权重进行评价。使用到的进化权重的算法为 (1+1)进化策略。该策略的伪代码如下： 第三行的调用检索了下一个个体来评估 (w)， a 和适应值在第八行给定。权重 w的向量用于便宜 rollout（第六行）。对于每个在 rollout 中找到的状态，首先 N 个数量的特征被提取（从状态空间\\(S\\)到特征空间\\(F\\)）。给定可行的动作 A，特征的权重和值制定了每个动作的相对强度 \\((a_i)\\)，如下列公式所示： $$a_i = \\sum_{j=1}^N w_{ij} \\times f_i$$ 这些动作都是经过特征加权过的动作，权重都存在矩阵 \\(W\\) 中，每一项 \\(w_{ij}\\) 代表对动作\\(i\\)经过特征 \\(j\\) 的权重。最后用一个softmax函数来选择门特卡罗模拟： $$P(a_i) = \\frac{e^{-a_i}}{\\sum^{A}_{j=1} e^{-a_j}}$$ 实际上，这些特征取决于游戏中特定精灵贴图的存在和消失，N特征的数量不仅每个游戏中不同，可能每个步骤中都不同。因此，该算法对于每个步骤中特征数量的加权需要更加灵活。 学习领域知识定义 KB Fast-Evo MCTS 的下一步便是增加一个可以提供更强力的你和函数系统来使得个体进化。你和实在rollout结束的时候计算的，目标是顶一个一个状态估计函数，这个函数的知识是在玩游戏的时候 动态学习的。 为了构建这个函数，知识库可以被分解为两个部分：好奇心 + 经验。好奇心指的是去发现与其他精灵贴图碰撞时产生的效果，经验 权衡那些能够提供分数增长的事件。事件记录可能是主角再碰到其他对象或者产生一些其他精灵贴图后提取的（如NPC，资源，非静态对象和传送门等）。每个 知识项 包含了以下统计数据： \\(Z_i\\): 事件 \\(i\\) 发生的概率 \\(\\bar{x_i}\\}: 分数的变化的平均值，即事件发生前后游戏分数之间的变化。多个事件在同一个游戏时间片中发生，可能无法确定哪个事件出发了得分变化。因此，事件发生概率 \\(Z_i\\)越大，分数变化平均值 \\(\\bar{x_i}\\)就越准确。 这两个值在蒙特卡洛模拟的每次前向模型调用时更新。当达到rollout结束时的状态，下面的值将被计算： 分数变化 \\(\\triangle R\\): 初始状态和结束状态之间的游戏分数变化 好奇心：知识改变 \\(\\triangle Z = \\sum_{i=1}^N \\triangle (K_i)\\)用于测量知识库中对于每个知识项\\(i\\)，所有 \\(Z_i\\) 的变化。\\(\\triangle (K_i)\\) 由下列公式计算，其中 \\(Z_{i0}\\)是 \\(Z_i\\) 的初始值，\\(Z_{iF}\\) 是\\(Z_i\\)的最终值。当 rollouts 产生更多事件时，\\(\\triangle Z\\) 会更高。如果某个事件非常稀有，则会提供较高的 \\(\\triangle Z\\) 值，有利于模拟中的知识收集。： $$\\triangle (K_i) = \\begin{cases} Z_{iF} &amp; Z_{i0} =0\\ \\frac{Z_{iF}}{Z_{i0}} -1 &amp; otherwise\\end{cases}$$ 经验： \\(\\triangle D = \\sum_{i=1}^{N} \\triangle (D_i)\\) 经验是一种从 rollout 开始到结束到每个类型为 \\(i\\) 精灵贴图的距离变化的度量。以下函数定义了 \\(\\triangle (D_i) \\)，其中 \\(D_{i0}\\) 是 rollout 开始时到最接近类型 \\(i\\) 精灵贴图的距离，\\(D_{if}\\) 是 rollout 结束时的距离。如果玩家在 rollout 期间与那些已知精灵贴图减少了 \\(\\bar{x_i}\\) 的距离而不是那些未知贴图的距离，那么 \\(\\triangle D\\) 就会变得更高。 $$\\triangle (D_i) = \\begin{cases}1-\\frac{D_{iF}}{D_{i0}} &amp; Z_{i0} =0\\ or\\ \\left( D_{i0} \\ &gt;0\\ and\\ \\overline{x_{i}} &gt;0\\right)\\0 &amp; otherwise\\end{cases}$$ 下列函数表示了游戏状态的最终值以及对于评估个体的拟合。这个值称为 \\(\\delta R \\)，除非 \\(\\triangle R =0 \\)。当其为0时，rollout 中的所有的动作都无法改变游戏分数。下列函数以 \\(\\alpha = 0.66\\) 和 \\(\\beta = 0.33\\) 为参数定义了一个线性函数： $$Reward = \\begin{cases}\\triangle R &amp; \\triangle R\\neq 0\\\\alpha \\triangleserifs Z\\ +\\ \\beta \\triangle D &amp; otherwise\\end{cases}$$ 因此，新的值函数将优先权分配给产生得分增加的动作。但如果没有分数增加的话，则把优先权分配给提供给知识库更多信息或者使玩家更接近提供分数精灵贴图的动作。","link":"/2021/04/12/GVGAI%20Book%20Chapter%203%20-%20Planning%20in%20GVGAI/"}],"tags":[{"name":"GVGAI; VGDL","slug":"GVGAI-VGDL","link":"/tags/GVGAI-VGDL/"},{"name":"joural","slug":"joural","link":"/tags/joural/"},{"name":"Gamemaker Studio","slug":"Gamemaker-Studio","link":"/tags/Gamemaker-Studio/"},{"name":"VGDL","slug":"VGDL","link":"/tags/VGDL/"},{"name":"GVGAI; AI","slug":"GVGAI-AI","link":"/tags/GVGAI-AI/"}],"categories":[]}